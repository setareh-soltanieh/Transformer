# Transformer Implementation

A simple, modular implementation of the Transformer architecture in Python using PyTorch.
Includes data preprocessing, tokenization, training, and evaluation.

## Features
- Tokenizers for English, French, and Italian
- Modular code: `dataset.py`, `model.py`, `config.py`, `train.py`
- Jupyter notebook (`Transformer.ipynb`) for step-by-step exploration
- Easy to adjust hyperparameters in `config.py`

## Installation
```bash
git clone https://github.com/setareh-soltanieh/Transformer.git
cd Transformer
```

## Usage

- Google Colab: open and run Transformer.ipynb
- Local machine: run the training script directly:
